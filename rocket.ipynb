{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glob\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from glob import glob\n",
    "from typing import Optional, Tuple\n",
    "import random\n",
    "\n",
    "import gradio as gr\n",
    "from diffusers import StableVideoDiffusionPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "max_64_bit_int = 2 ** 63 - 1\n",
    "output_folder = \"outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
    "    \"/app/models/stabilityai/stable-video-diffusion-img2vid-xt\",\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)\n",
    "pipe.vae = torch.compile(pipe.vae, mode=\"reduce-overhead\", fullgraph=True)\n",
    "\n",
    "# According to your actual needs\n",
    "#\n",
    "# pipe.enable_model_cpu_offload()\n",
    "# pipe.unet.enable_forward_chunking()\n",
    "\n",
    "def sample(\n",
    "    image: Image,\n",
    "    seed: Optional[int] = 42,\n",
    "    randomize_seed: bool = True,\n",
    "    motion_bucket_id: int = 127,\n",
    "    fps_id: int = 6,\n",
    "    version: str = \"svd_xt\",\n",
    "    cond_aug: float = 0.02,\n",
    "    decoding_t: int = 3,  # Number of frames decoded at a time! This eats most VRAM. Reduce if necessary.\n",
    "    device: str = \"cuda\",\n",
    "    output_folder: str = output_folder,\n",
    "):\n",
    "\n",
    "    if randomize_seed:\n",
    "        seed = random.randint(0, max_64_bit_int)\n",
    "\n",
    "    base_count = len(glob(os.path.join(output_folder, \"*.mp4\")))\n",
    "    video_path = os.path.join(output_folder, f\"{base_count:06d}.mp4\")\n",
    "\n",
    "    frames = pipe(\n",
    "        image,\n",
    "        decode_chunk_size=decoding_t,\n",
    "        generator=torch.manual_seed(seed),\n",
    "        motion_bucket_id=motion_bucket_id,\n",
    "        noise_aug_strength=0.1,\n",
    "        num_frames=25,\n",
    "    ).frames[0]\n",
    "\n",
    "    export_to_video(frames, video_path, fps=fps_id)\n",
    "\n",
    "    return video_path, seed\n",
    "\n",
    "\n",
    "def resize_image(image: Image, output_size: Tuple[int, int] =(1024, 576)):\n",
    "    # Calculate aspect ratios\n",
    "    target_aspect = output_size[0] / output_size[1]  # Aspect ratio of the desired size\n",
    "    image_aspect = image.width / image.height  # Aspect ratio of the original image\n",
    "\n",
    "    # Resize then crop if the original image is larger\n",
    "    if image_aspect > target_aspect:\n",
    "        # Resize the image to match the target height, maintaining aspect ratio\n",
    "        new_height = output_size[1]\n",
    "        new_width = int(new_height * image_aspect)\n",
    "        resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        # Calculate coordinates for cropping\n",
    "        left = (new_width - output_size[0]) / 2\n",
    "        top = 0\n",
    "        right = (new_width + output_size[0]) / 2\n",
    "        bottom = output_size[1]\n",
    "    else:\n",
    "        # Resize the image to match the target width, maintaining aspect ratio\n",
    "        new_width = output_size[0]\n",
    "        new_height = int(new_width / image_aspect)\n",
    "        resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        # Calculate coordinates for cropping\n",
    "        left = 0\n",
    "        top = (new_height - output_size[1]) / 2\n",
    "        right = output_size[0]\n",
    "        bottom = (new_height + output_size[1]) / 2\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_image = resized_image.crop((left, top, right, bottom))\n",
    "    # set correct image mode\n",
    "    if cropped_image.mode == \"RGBA\":\n",
    "        cropped_image = cropped_image.convert(\"RGB\")\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "def generate(image, seed, randomize_seed, motion_bucket_id, fps_id):\n",
    "    img = resize_image(image, output_size=(1024, 576))\n",
    "    video, seed = sample(img, seed, randomize_seed, motion_bucket_id, fps_id)\n",
    "    return video, seed\n",
    "\n",
    "\n",
    "app = gr.Interface(\n",
    "    fn=generate,\n",
    "    inputs=[\n",
    "        gr.Image(label=\"Upload your image\", type=\"pil\"),\n",
    "        gr.Slider(\n",
    "            label=\"Seed\",\n",
    "            value=42,\n",
    "            randomize=True,\n",
    "            minimum=0,\n",
    "            maximum=max_64_bit_int,\n",
    "            step=1,\n",
    "        ),\n",
    "        gr.Checkbox(label=\"Randomize seed\", value=True),\n",
    "        gr.Slider(\n",
    "            label=\"Motion bucket id\",\n",
    "            info=\"Controls how much motion to add/remove from the image\",\n",
    "            value=127,\n",
    "            minimum=1,\n",
    "            maximum=255,\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            label=\"Frames per second\",\n",
    "            info=\"The length of your video in seconds will be 25/fps\",\n",
    "            value=6,\n",
    "            minimum=5,\n",
    "            maximum=30,\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.PlayableVideo(label=\"Generated video\"),\n",
    "        gr.Textbox(label=\"Seed\", type=\"text\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.queue(max_size=2)\n",
    "    app.launch(share=False, server_name=\"0.0.0.0\", ssl_verify=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
